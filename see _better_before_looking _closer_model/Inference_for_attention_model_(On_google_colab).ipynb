{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Inference for attention model (On google colab).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XUi_oPuUIX"
      },
      "source": [
        "# Mounting drive where we are going to store the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-psSqsPs55b",
        "outputId": "d8e8f682-d184-4df8-eb01-809748f4eee6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aISyNJ1bgvnZ"
      },
      "source": [
        "Making the validation dataset representative ( 85% train, 15% validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2y_QQp6IWLX",
        "outputId": "ea4283bc-2047-4408-b14c-95246ced7cf0"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "path_data = \"/content/drive/MyDrive/Birds/bird_dataset\"\n",
        "\n",
        "for entry in os.listdir(path_data+\"/train_images\"):\n",
        "  train_entry = path_data+\"/train_images/\"+entry\n",
        "  nbr_train = len(os.listdir(train_entry))\n",
        "  val_entry = path_data+\"/val_images/\"+entry\n",
        "  nbr_val = len(os.listdir(val_entry))\n",
        "  i = max(0, int ((nbr_train+nbr_val)*0.15-nbr_val)) ## splitting almost 90%-10%\n",
        "  print(\"nbr of moved images\", i)\n",
        "  for image in os.listdir(train_entry):\n",
        "    if i>0:\n",
        "      shutil.move(train_entry+\"/\"+image, val_entry+\"/\"+image)\n",
        "      i = i-1\n",
        "    else:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nbr of moved images 3\n",
            "nbr of moved images 1\n",
            "nbr of moved images 3\n",
            "nbr of moved images 1\n",
            "nbr of moved images 3\n",
            "nbr of moved images 2\n",
            "nbr of moved images 0\n",
            "nbr of moved images 2\n",
            "nbr of moved images 3\n",
            "nbr of moved images 0\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 2\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 3\n",
            "nbr of moved images 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxIBGILOwUru"
      },
      "source": [
        "# Installing and preparing the necessary dependencies to run the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoDgpZALpihu",
        "outputId": "d5a2207a-e1a5-4e12-88fa-a5e3751be040"
      },
      "source": [
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "# update 1\n",
        "!conda install -q -y --prefix /usr/local python=3.6 ujson\n",
        "# update 2\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.6/site-packages')\n",
        "# test it\n",
        "import json\n",
        "print(json.dumps({1:2}))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-20 16:06:22--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-4.5.4-Li 100%[===================>]  55.76M   149MB/s    in 0.4s    \n",
            "\n",
            "2021-11-20 16:06:23 (149 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - python=3.6\n",
            "    - ujson\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    pip-21.2.2                 |   py36h06a4308_0         2.1 MB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    python-3.6.13              |       h12debd9_1        32.5 MB\n",
            "    certifi-2021.5.30          |   py36h06a4308_0         141 KB\n",
            "    setuptools-58.0.4          |   py36h06a4308_0         979 KB\n",
            "    ujson-4.0.2                |   py36h2531618_0          48 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    tk-8.6.11                  |       h1ccaba5_0         3.2 MB\n",
            "    ld_impl_linux-64-2.35.1    |       h7274673_9         637 KB\n",
            "    readline-8.1               |       h27cfd23_0         464 KB\n",
            "    wheel-0.37.0               |     pyhd3eb1b0_1          31 KB\n",
            "    sqlite-3.36.0              |       hc218d9a_0         1.4 MB\n",
            "    openssl-1.1.1l             |       h7f8727e_0         3.8 MB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    ca-certificates-2021.10.26 |       h06a4308_2         121 KB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    ncurses-6.3                |       h7f8727e_2         1.0 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        59.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:    0.1-main            \n",
            "    ld_impl_linux-64: 2.35.1-h7274673_9   \n",
            "    ujson:            4.0.2-py36h2531618_0\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:  2018.03.07-0         --> 2021.10.26-h06a4308_2   \n",
            "    certifi:          2018.4.16-py36_0     --> 2021.5.30-py36h06a4308_0\n",
            "    libffi:           3.2.1-hd88cf55_4     --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:        7.2.0-hdf63c60_3     --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:     7.2.0-hdf63c60_3     --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:          6.1-hf484d3e_0       --> 6.3-h7f8727e_2          \n",
            "    openssl:          1.0.2o-h20670df_0    --> 1.1.1l-h7f8727e_0       \n",
            "    pip:              10.0.1-py36_0        --> 21.2.2-py36h06a4308_0   \n",
            "    python:           3.6.5-hc3d631a_2     --> 3.6.13-h12debd9_1       \n",
            "    readline:         7.0-ha6073c6_4       --> 8.1-h27cfd23_0          \n",
            "    setuptools:       39.2.0-py36_0        --> 58.0.4-py36h06a4308_0   \n",
            "    sqlite:           3.23.1-he433501_0    --> 3.36.0-hc218d9a_0       \n",
            "    tk:               8.6.7-hc745277_3     --> 8.6.11-h1ccaba5_0       \n",
            "    wheel:            0.31.1-py36_0        --> 0.37.0-pyhd3eb1b0_1     \n",
            "    xz:               5.2.4-h14c3975_4     --> 5.2.5-h7b6447c_0        \n",
            "    zlib:             1.2.11-ha838bed_2    --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "{\"1\": 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_nMRrooTKr_",
        "outputId": "b9d07dfc-b3a9-4ec0-e53d-c8f8ebc79b3d"
      },
      "source": [
        "!pip install Pillow==6.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==6.1\n",
            "  Downloading Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-6.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "WmY9yX5_TK5t",
        "outputId": "d51da8a8-f99b-438c-a2d7-5610fd54b6ac"
      },
      "source": [
        "!pip install torch torchvision\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.4 MB/s eta 0:00:34tcmalloc: large alloc 1147494400 bytes == 0x55dae4784000 @  0x7f579948e615 0x55da80656455 0x55da805a9e84 0x55da805b54aa 0x55da806a2f14 0x55da806c039f 0x55da80650160 0x55da8068d41b 0x55da806a30f7 0x55da806c039f 0x55da80650160 0x55da8068d41b 0x55da806a30f7 0x55da806c1a1e 0x55da80661610 0x55da806c0972 0x55da80661610 0x55da806c0972 0x55da80661610 0x55da806c0972 0x55da80693044 0x55da806529fe 0x55da8069990c 0x55da8065128c 0x55da806a3135 0x55da806c039f 0x55da80650160 0x55da8068d41b 0x55da806a30f7 0x55da806c1a1e 0x55da80650160\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 893 bytes/s \n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.11.1-cp36-cp36m-manylinux1_x86_64.whl (23.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.3 MB 66 kB/s \n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.6/site-packages (from torchvision) (6.1.0)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 173 kB/s \n",
            "\u001b[?25hInstalling collected packages: typing-extensions, dataclasses, torch, numpy, torchvision\n",
            "Successfully installed dataclasses-0.8 numpy-1.19.5 torch-1.10.0 torchvision-0.11.1 typing-extensions-4.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct-ikguGTKny",
        "outputId": "6002858a-08ab-43de-cf79-281000d06af0"
      },
      "source": [
        "!pip install torch\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/site-packages (1.10.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from torch) (4.0.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpnqF1OVTKkM",
        "outputId": "9f34fa43-59db-4a52-c224-a3d260155e1b"
      },
      "source": [
        "!pip install scipy\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scipy\n",
            "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 41 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.6/site-packages (from scipy) (1.19.5)\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.5.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_48nCODTKgx",
        "outputId": "8f2f2112-72e3-49e6-f32a-676a3f9f3076"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/site-packages (0.11.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.6/site-packages (from torchvision) (1.10.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.6/site-packages (from torchvision) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/site-packages (from torch==1.10.0->torchvision) (4.0.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/site-packages (from torch==1.10.0->torchvision) (0.8)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixoCiDHoTEqI",
        "outputId": "d13edf4b-f9cf-4061-a2a4-dba92fede906"
      },
      "source": [
        "!pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (703.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 703.8 MB 17 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.0%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 28.5 MB/s \n",
            "\u001b[?25hCollecting future\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from torch==1.5.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/site-packages (from torchvision==0.6.0+cu101) (6.1.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e0ff09675dac4c47a985232bb852ba8091c9a42fef3b4e40cbedc654126031af\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/9c/ed/4499c9865ac1002697793e0ae05ba6be33553d098f3347fb94\n",
            "Successfully built future\n",
            "Installing collected packages: future, torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0\n",
            "    Uninstalling torch-1.10.0:\n",
            "      Successfully uninstalled torch-1.10.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1\n",
            "    Uninstalling torchvision-0.11.1:\n",
            "      Successfully uninstalled torchvision-0.11.1\n",
            "Successfully installed future-0.18.2 torch-1.5.0+cu101 torchvision-0.6.0+cu101\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wJC3bcs85P5",
        "outputId": "794fcb71-161b-454e-c5c1-e07333f5e3ab"
      },
      "source": [
        "pip install tqdm"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 20 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 30 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 40 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 76 kB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.62.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "f5vOSD0LHgPF",
        "outputId": "943b909e-42c2-48c0-e91a-70b318f1310c"
      },
      "source": [
        "pip install prettytable"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prettytable\n",
            "  Downloading prettytable-2.4.0-py3-none-any.whl (24 kB)\n",
            "Collecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting importlib-metadata\n",
            "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.6/site-packages (from importlib-metadata->prettytable) (4.0.0)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: zipp, wcwidth, importlib-metadata, prettytable\n",
            "Successfully installed importlib-metadata-4.8.2 prettytable-2.4.0 wcwidth-0.2.5 zipp-3.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZTFdyvQwyqV"
      },
      "source": [
        "# Train Script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HN-z58CLm1W"
      },
      "source": [
        "Training using inception v3 as backbone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvzOrftCJwHa",
        "outputId": "faaffa1a-436a-4ac6-cd40-ac62d40d704b"
      },
      "source": [
        "%cd /content/drive/'My Drive'/WS_DAN_PyTorch-master\n",
        "!python train_bap.py train\\\n",
        "    --model-name inception \\\n",
        "    --batch-size 64 \\\n",
        "    --dataset bird \\\n",
        "    --image-size 300 \\\n",
        "    --input-size 300 \\\n",
        "    --checkpoint-path /content/drive/'My Drive'/WS_DAN_PyTorch-master/checkpoint/bird \\\n",
        "    --optim sgd \\\n",
        "    --scheduler step \\\n",
        "    --lr 0.001 \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-5 \\\n",
        "    --workers 4 \\\n",
        "    --parts 32 \\\n",
        "    --epochs 80 \\\n",
        "    --use-gpu \\\n",
        "    --multi-gpu \\\n",
        "    --gpu-ids 0 \\"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/WS_DAN_PyTorch-master\n",
            "Dataset Name:bird, Train:[1015], Val:[170]\n",
            "Batch Size:[64], Total:::Train Batches:[16],Val Batches:[3]\n",
            "+------------------------------------+------------+\n",
            "|              Modules               | Parameters |\n",
            "+------------------------------------+------------+\n",
            "|  Mixed_7a.branch3x3_1.conv.weight  |   147456   |\n",
            "|   Mixed_7a.branch3x3_1.bn.weight   |    192     |\n",
            "|    Mixed_7a.branch3x3_1.bn.bias    |    192     |\n",
            "|  Mixed_7a.branch3x3_2.conv.weight  |   552960   |\n",
            "|   Mixed_7a.branch3x3_2.bn.weight   |    320     |\n",
            "|    Mixed_7a.branch3x3_2.bn.bias    |    320     |\n",
            "| Mixed_7a.branch7x7x3_1.conv.weight |   147456   |\n",
            "|  Mixed_7a.branch7x7x3_1.bn.weight  |    192     |\n",
            "|   Mixed_7a.branch7x7x3_1.bn.bias   |    192     |\n",
            "| Mixed_7a.branch7x7x3_2.conv.weight |   258048   |\n",
            "|  Mixed_7a.branch7x7x3_2.bn.weight  |    192     |\n",
            "|   Mixed_7a.branch7x7x3_2.bn.bias   |    192     |\n",
            "| Mixed_7a.branch7x7x3_3.conv.weight |   258048   |\n",
            "|  Mixed_7a.branch7x7x3_3.bn.weight  |    192     |\n",
            "|   Mixed_7a.branch7x7x3_3.bn.bias   |    192     |\n",
            "| Mixed_7a.branch7x7x3_4.conv.weight |   331776   |\n",
            "|  Mixed_7a.branch7x7x3_4.bn.weight  |    192     |\n",
            "|   Mixed_7a.branch7x7x3_4.bn.bias   |    192     |\n",
            "|           fc_new.weight            |   491520   |\n",
            "|            fc_new.bias             |     20     |\n",
            "+------------------------------------+------------+\n",
            "Total Trainable Params: 2189844\n",
            "2189844\n",
            "Namespace(action='train', alpha=0.95, batch_size=64, checkpoint_path='/content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird', dataset='bird', epochs=80, gpu_ids='0', image_size=300, input_size=300, lr=0.001, model_name='inception', momentum=0.9, multi_gpu=True, optim='sgd', parts=32, print_freq=100, resume='', scheduler='step', use_gpu=True, weight_decay=1e-05, workers=4)\n",
            "/usr/local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Start epoch 0 ==========,lr=0.001000\n",
            "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "Epoch: [0][0/16]\tLoss 4.0679 (4.0679)\tAccuracy 0.000 (0.000)\t\n",
            "loss1,loss2,feature_center_loss 3.085320234298706 3.050431966781616 1.0\n",
            "Epoch: [0][4/16]\tLoss 3.7321 (3.6760)\tAccuracy 4.688 (3.125)\t\n",
            "loss1,loss2,feature_center_loss 3.2010657787323 3.2258613109588623 0.5186477899551392\n",
            "Epoch: [0][8/16]\tLoss 3.6740 (3.6525)\tAccuracy 7.812 (3.993)\t\n",
            "loss1,loss2,feature_center_loss 3.1117172241210938 3.1309266090393066 0.5527169108390808\n",
            "Epoch: [0][12/16]\tLoss 3.5826 (3.6333)\tAccuracy 15.625 (6.370)\t\n",
            "loss1,loss2,feature_center_loss 3.0422797203063965 3.0788307189941406 0.5220237970352173\n",
            "Test: [0/3]\tLoss 3.6507 (3.6507)\tAccuracy 4.688 (4.688)\t\n",
            "Test: [1/3]\tLoss 3.3482 (3.4995)\tAccuracy 23.438 (14.062)\t\n",
            "Test: [2/3]\tLoss 3.0758 (3.3948)\tAccuracy 9.524 (12.941)\t\n",
            "  Validation : Accuracy1 12.941 Loss : 3.395 \n",
            "Save best model at /content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/model_best.pth.tar==\n",
            "Start epoch 1 ==========,lr=0.000900\n",
            "Epoch: [1][0/16]\tLoss 3.1813 (3.1813)\tAccuracy 14.062 (14.062)\t\n",
            "loss1,loss2,feature_center_loss 2.653749465942383 2.6976253986358643 0.50559401512146\n",
            "Epoch: [1][4/16]\tLoss 2.8213 (3.0780)\tAccuracy 21.875 (26.562)\t\n",
            "loss1,loss2,feature_center_loss 2.2572383880615234 2.3652021884918213 0.5101273059844971\n",
            "Epoch: [1][8/16]\tLoss 2.8209 (3.0423)\tAccuracy 37.500 (27.951)\t\n",
            "loss1,loss2,feature_center_loss 2.1793527603149414 2.375983715057373 0.5432084798812866\n",
            "Epoch: [1][12/16]\tLoss 2.7881 (2.9397)\tAccuracy 29.688 (31.490)\t\n",
            "loss1,loss2,feature_center_loss 2.200723171234131 2.322038412094116 0.5267446041107178\n",
            "Test: [0/3]\tLoss 2.9439 (2.9439)\tAccuracy 35.938 (35.938)\t\n",
            "Test: [1/3]\tLoss 2.6633 (2.8036)\tAccuracy 48.438 (42.188)\t\n",
            "Test: [2/3]\tLoss 2.2739 (2.6727)\tAccuracy 61.905 (47.059)\t\n",
            "  Validation : Accuracy1 47.059 Loss : 2.673 \n",
            "Save best model at /content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/model_best.pth.tar==\n",
            "Start epoch 2 ==========,lr=0.000900\n",
            "Epoch: [2][0/16]\tLoss 2.4108 (2.4108)\tAccuracy 53.125 (53.125)\t\n",
            "loss1,loss2,feature_center_loss 1.7943589687347412 1.9642040729522705 0.5315625667572021\n",
            "Epoch: [2][4/16]\tLoss 2.4227 (2.3913)\tAccuracy 53.125 (55.938)\t\n",
            "loss1,loss2,feature_center_loss 1.707147240638733 2.0290708541870117 0.5546140670776367\n",
            "Epoch: [2][8/16]\tLoss 2.1301 (2.2888)\tAccuracy 56.250 (58.507)\t\n",
            "loss1,loss2,feature_center_loss 1.482362985610962 1.6858454942703247 0.5460159778594971\n",
            "Epoch: [2][12/16]\tLoss 2.0545 (2.2071)\tAccuracy 67.188 (61.058)\t\n",
            "loss1,loss2,feature_center_loss 1.3435838222503662 1.6492221355438232 0.5581331253051758\n",
            "Test: [0/3]\tLoss 2.3175 (2.3175)\tAccuracy 57.812 (57.812)\t\n",
            "Test: [1/3]\tLoss 2.0183 (2.1679)\tAccuracy 59.375 (58.594)\t\n",
            "Test: [2/3]\tLoss 2.6814 (2.2948)\tAccuracy 23.810 (50.000)\t\n",
            "  Validation : Accuracy1 50.000 Loss : 2.295 \n",
            "Save best model at /content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/model_best.pth.tar==\n",
            "Start epoch 3 ==========,lr=0.000810\n",
            "Epoch: [3][0/16]\tLoss 1.9703 (1.9703)\tAccuracy 60.938 (60.938)\t\n",
            "loss1,loss2,feature_center_loss 1.3137811422348022 1.5095449686050415 0.5586715936660767\n",
            "Epoch: [3][4/16]\tLoss 1.9055 (1.8447)\tAccuracy 68.750 (67.188)\t\n",
            "loss1,loss2,feature_center_loss 1.1861881017684937 1.4551262855529785 0.5848394632339478\n",
            "Epoch: [3][8/16]\tLoss 1.7237 (1.7824)\tAccuracy 73.438 (70.312)\t\n",
            "loss1,loss2,feature_center_loss 0.9789410829544067 1.3196114301681519 0.574388861656189\n",
            "Epoch: [3][12/16]\tLoss 1.6153 (1.7343)\tAccuracy 81.250 (72.837)\t\n",
            "loss1,loss2,feature_center_loss 0.9660909175872803 1.1175894737243652 0.5734237432479858\n",
            "Test: [0/3]\tLoss 1.8947 (1.8947)\tAccuracy 78.125 (78.125)\t\n",
            "Test: [1/3]\tLoss 1.6389 (1.7668)\tAccuracy 81.250 (79.688)\t\n",
            "Test: [2/3]\tLoss 2.3443 (1.9095)\tAccuracy 52.381 (72.941)\t\n",
            "  Validation : Accuracy1 72.941 Loss : 1.909 \n",
            "Save best model at /content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/model_best.pth.tar==\n",
            "Start epoch 4 ==========,lr=0.000810\n",
            "Epoch: [4][0/16]\tLoss 1.5924 (1.5924)\tAccuracy 75.000 (75.000)\t\n",
            "loss1,loss2,feature_center_loss 0.8720874190330505 1.1435651779174805 0.5845475792884827\n",
            "Epoch: [4][4/16]\tLoss 1.3500 (1.3972)\tAccuracy 87.500 (85.312)\t\n",
            "loss1,loss2,feature_center_loss 0.6268170475959778 0.926114559173584 0.5735492706298828\n",
            "Epoch: [4][8/16]\tLoss 1.4299 (1.4125)\tAccuracy 84.375 (85.069)\t\n",
            "loss1,loss2,feature_center_loss 0.680908203125 1.0217831134796143 0.5785510540008545\n",
            "Traceback (most recent call last):\n",
            "  File \"train_bap.py\", line 255, in <module>\n",
            "    train()\n",
            "  File \"train_bap.py\", line 177, in train\n",
            "    train_prec, train_loss = engine.train(state, e)\n",
            "  File \"/content/drive/My Drive/WS_DAN_PyTorch-master/utils/engine.py\", line 38, in train\n",
            "    for i, (img, label) in enumerate(train_loader):\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 345, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 385, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 135, in __getitem__\n",
            "    sample = self.loader(path)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 171, in default_loader\n",
            "    return pil_loader(path)\n",
            "  File \"/usr/local/lib/python3.6/site-packages/torchvision/datasets/folder.py\", line 152, in pil_loader\n",
            "    with open(path, 'rb') as f:\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO1JrQRkfobh",
        "outputId": "26d1c616-df3e-4989-f08c-4e7962154d70"
      },
      "source": [
        "%cd /content/drive/'My Drive'/WS_DAN_PyTorch-master\n",
        "!python train_bap.py train\\\n",
        "    --model-name resnet50 \\\n",
        "    --batch-size 16 \\\n",
        "    --dataset bird \\\n",
        "    --image-size 300 \\\n",
        "    --input-size 300 \\\n",
        "    --checkpoint-path /content/drive/'My Drive'/WS_DAN_PyTorch-master/checkpoint/bird/Resnet \\\n",
        "    --optim sgd \\\n",
        "    --scheduler step \\\n",
        "    --lr 0.001 \\\n",
        "    --momentum 0.9 \\\n",
        "    --weight-decay 1e-5 \\\n",
        "    --workers 4 \\\n",
        "    --parts 32 \\\n",
        "    --epochs 80 \\\n",
        "    --use-gpu \\\n",
        "    --multi-gpu \\\n",
        "    --gpu-ids 0 \\"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/WS_DAN_PyTorch-master\n",
            "Dataset Name:bird, Train:[1015], Val:[170]\n",
            "Batch Size:[16], Total:::Train Batches:[64],Val Batches:[11]\n",
            "+------------------------------+------------+\n",
            "|           Modules            | Parameters |\n",
            "+------------------------------+------------+\n",
            "|    layer2.0.conv1.weight     |   32768    |\n",
            "|     layer2.0.bn1.weight      |    128     |\n",
            "|      layer2.0.bn1.bias       |    128     |\n",
            "|    layer2.0.conv2.weight     |   147456   |\n",
            "|     layer2.0.bn2.weight      |    128     |\n",
            "|      layer2.0.bn2.bias       |    128     |\n",
            "|    layer2.0.conv3.weight     |   65536    |\n",
            "|     layer2.0.bn3.weight      |    512     |\n",
            "|      layer2.0.bn3.bias       |    512     |\n",
            "| layer2.0.downsample.0.weight |   131072   |\n",
            "| layer2.0.downsample.1.weight |    512     |\n",
            "|  layer2.0.downsample.1.bias  |    512     |\n",
            "|    layer2.1.conv1.weight     |   65536    |\n",
            "|     layer2.1.bn1.weight      |    128     |\n",
            "|      layer2.1.bn1.bias       |    128     |\n",
            "|    layer2.1.conv2.weight     |   147456   |\n",
            "|     layer2.1.bn2.weight      |    128     |\n",
            "|      layer2.1.bn2.bias       |    128     |\n",
            "|    layer2.1.conv3.weight     |   65536    |\n",
            "|     layer2.1.bn3.weight      |    512     |\n",
            "|      layer2.1.bn3.bias       |    512     |\n",
            "|    layer2.2.conv1.weight     |   65536    |\n",
            "|     layer2.2.bn1.weight      |    128     |\n",
            "|      layer2.2.bn1.bias       |    128     |\n",
            "|    layer2.2.conv2.weight     |   147456   |\n",
            "|     layer2.2.bn2.weight      |    128     |\n",
            "|      layer2.2.bn2.bias       |    128     |\n",
            "|    layer2.2.conv3.weight     |   65536    |\n",
            "|     layer2.2.bn3.weight      |    512     |\n",
            "|      layer2.2.bn3.bias       |    512     |\n",
            "|    layer2.3.conv1.weight     |   65536    |\n",
            "|     layer2.3.bn1.weight      |    128     |\n",
            "|      layer2.3.bn1.bias       |    128     |\n",
            "|    layer2.3.conv2.weight     |   147456   |\n",
            "|     layer2.3.bn2.weight      |    128     |\n",
            "|      layer2.3.bn2.bias       |    128     |\n",
            "|    layer2.3.conv3.weight     |   65536    |\n",
            "|     layer2.3.bn3.weight      |    512     |\n",
            "|      layer2.3.bn3.bias       |    512     |\n",
            "|    layer3.0.conv1.weight     |   131072   |\n",
            "|     layer3.0.bn1.weight      |    256     |\n",
            "|      layer3.0.bn1.bias       |    256     |\n",
            "|    layer3.0.conv2.weight     |   589824   |\n",
            "|     layer3.0.bn2.weight      |    256     |\n",
            "|      layer3.0.bn2.bias       |    256     |\n",
            "|    layer3.0.conv3.weight     |   262144   |\n",
            "|     layer3.0.bn3.weight      |    1024    |\n",
            "|      layer3.0.bn3.bias       |    1024    |\n",
            "| layer3.0.downsample.0.weight |   524288   |\n",
            "| layer3.0.downsample.1.weight |    1024    |\n",
            "|  layer3.0.downsample.1.bias  |    1024    |\n",
            "|    layer3.1.conv1.weight     |   262144   |\n",
            "|     layer3.1.bn1.weight      |    256     |\n",
            "|      layer3.1.bn1.bias       |    256     |\n",
            "|    layer3.1.conv2.weight     |   589824   |\n",
            "|     layer3.1.bn2.weight      |    256     |\n",
            "|      layer3.1.bn2.bias       |    256     |\n",
            "|    layer3.1.conv3.weight     |   262144   |\n",
            "|     layer3.1.bn3.weight      |    1024    |\n",
            "|      layer3.1.bn3.bias       |    1024    |\n",
            "|    layer3.2.conv1.weight     |   262144   |\n",
            "|     layer3.2.bn1.weight      |    256     |\n",
            "|      layer3.2.bn1.bias       |    256     |\n",
            "|    layer3.2.conv2.weight     |   589824   |\n",
            "|     layer3.2.bn2.weight      |    256     |\n",
            "|      layer3.2.bn2.bias       |    256     |\n",
            "|    layer3.2.conv3.weight     |   262144   |\n",
            "|     layer3.2.bn3.weight      |    1024    |\n",
            "|      layer3.2.bn3.bias       |    1024    |\n",
            "|    layer3.3.conv1.weight     |   262144   |\n",
            "|     layer3.3.bn1.weight      |    256     |\n",
            "|      layer3.3.bn1.bias       |    256     |\n",
            "|    layer3.3.conv2.weight     |   589824   |\n",
            "|     layer3.3.bn2.weight      |    256     |\n",
            "|      layer3.3.bn2.bias       |    256     |\n",
            "|    layer3.3.conv3.weight     |   262144   |\n",
            "|     layer3.3.bn3.weight      |    1024    |\n",
            "|      layer3.3.bn3.bias       |    1024    |\n",
            "|    layer3.4.conv1.weight     |   262144   |\n",
            "|     layer3.4.bn1.weight      |    256     |\n",
            "|      layer3.4.bn1.bias       |    256     |\n",
            "|    layer3.4.conv2.weight     |   589824   |\n",
            "|     layer3.4.bn2.weight      |    256     |\n",
            "|      layer3.4.bn2.bias       |    256     |\n",
            "|    layer3.4.conv3.weight     |   262144   |\n",
            "|     layer3.4.bn3.weight      |    1024    |\n",
            "|      layer3.4.bn3.bias       |    1024    |\n",
            "|    layer3.5.conv1.weight     |   262144   |\n",
            "|     layer3.5.bn1.weight      |    256     |\n",
            "|      layer3.5.bn1.bias       |    256     |\n",
            "|    layer3.5.conv2.weight     |   589824   |\n",
            "|     layer3.5.bn2.weight      |    256     |\n",
            "|      layer3.5.bn2.bias       |    256     |\n",
            "|    layer3.5.conv3.weight     |   262144   |\n",
            "|     layer3.5.bn3.weight      |    1024    |\n",
            "|      layer3.5.bn3.bias       |    1024    |\n",
            "|    layer4.0.conv1.weight     |   524288   |\n",
            "|     layer4.0.bn1.weight      |    512     |\n",
            "|      layer4.0.bn1.bias       |    512     |\n",
            "|    layer4.0.conv2.weight     |  2359296   |\n",
            "|     layer4.0.bn2.weight      |    512     |\n",
            "|      layer4.0.bn2.bias       |    512     |\n",
            "|    layer4.0.conv3.weight     |  1048576   |\n",
            "|     layer4.0.bn3.weight      |    2048    |\n",
            "|      layer4.0.bn3.bias       |    2048    |\n",
            "| layer4.0.downsample.0.weight |  2097152   |\n",
            "| layer4.0.downsample.1.weight |    2048    |\n",
            "|  layer4.0.downsample.1.bias  |    2048    |\n",
            "|    layer4.1.conv1.weight     |  1048576   |\n",
            "|     layer4.1.bn1.weight      |    512     |\n",
            "|      layer4.1.bn1.bias       |    512     |\n",
            "|    layer4.1.conv2.weight     |  2359296   |\n",
            "|     layer4.1.bn2.weight      |    512     |\n",
            "|      layer4.1.bn2.bias       |    512     |\n",
            "|    layer4.1.conv3.weight     |  1048576   |\n",
            "|     layer4.1.bn3.weight      |    2048    |\n",
            "|      layer4.1.bn3.bias       |    2048    |\n",
            "|        fc_new.weight         |   327680   |\n",
            "|         fc_new.bias          |     20     |\n",
            "+------------------------------+------------+\n",
            "Total Trainable Params: 19147796\n",
            "19147796\n",
            "Namespace(action='train', alpha=0.95, batch_size=16, checkpoint_path='/content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/Resnet', dataset='bird', epochs=80, gpu_ids='0', image_size=300, input_size=300, lr=0.001, model_name='resnet50', momentum=0.9, multi_gpu=True, optim='sgd', parts=32, print_freq=100, resume='', scheduler='step', use_gpu=True, weight_decay=1e-05, workers=4)\n",
            "/usr/local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "Start epoch 0 ==========,lr=0.001000\n",
            "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "Epoch: [0][0/64]\tLoss 1.0103 (1.0103)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.003025949001312256 0.0176161527633667 1.0\n",
            "Epoch: [0][4/64]\tLoss 0.2429 (0.4501)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.004470765590667725 0.019141077995300293 0.2310672551393509\n",
            "Epoch: [0][8/64]\tLoss 0.2604 (0.3474)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.006015598773956299 0.08524647355079651 0.21479842066764832\n",
            "Epoch: [0][12/64]\tLoss 0.1649 (0.3048)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0012206435203552246 0.015047937631607056 0.15680131316184998\n",
            "Epoch: [0][16/64]\tLoss 0.2218 (0.2834)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0022942423820495605 0.08941560983657837 0.17592516541481018\n",
            "Epoch: [0][20/64]\tLoss 0.1904 (0.2687)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0023995637893676758 0.016536086797714233 0.18092799186706543\n",
            "Epoch: [0][24/64]\tLoss 0.1891 (0.2592)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0025392770767211914 0.03365659713745117 0.17101696133613586\n",
            "Epoch: [0][28/64]\tLoss 0.2144 (0.2516)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0031499266624450684 0.06543058156967163 0.18008939921855927\n",
            "Epoch: [0][32/64]\tLoss 0.2287 (0.2475)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.002268373966217041 0.09649601578712463 0.17931969463825226\n",
            "Epoch: [0][36/64]\tLoss 0.2331 (0.2442)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.006156563758850098 0.07073092460632324 0.19464410841464996\n",
            "Epoch: [0][40/64]\tLoss 0.2528 (0.2411)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.012419283390045166 0.1415928304195404 0.17582747340202332\n",
            "Epoch: [0][44/64]\tLoss 0.2628 (0.2392)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.025337964296340942 0.14300775527954102 0.17866699397563934\n",
            "Epoch: [0][48/64]\tLoss 0.1911 (0.2371)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0009553432464599609 0.0035451650619506836 0.1888916790485382\n",
            "Epoch: [0][52/64]\tLoss 0.2574 (0.2352)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.008726894855499268 0.13973641395568848 0.18319633603096008\n",
            "Epoch: [0][56/64]\tLoss 0.1673 (0.2327)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0006497502326965332 0.044499218463897705 0.144677072763443\n",
            "Epoch: [0][60/64]\tLoss 0.2115 (0.2324)\tAccuracy 100.000 (99.898)\t\n",
            "loss1,loss2,feature_center_loss 0.0017058253288269043 0.010999619960784912 0.20518863201141357\n",
            "Test: [0/11]\tLoss 0.4952 (0.4952)\tAccuracy 100.000 (100.000)\t\n",
            "Test: [1/11]\tLoss 0.4972 (0.4962)\tAccuracy 93.750 (96.875)\t\n",
            "Test: [2/11]\tLoss 0.4119 (0.4681)\tAccuracy 100.000 (97.917)\t\n",
            "Test: [3/11]\tLoss 0.2529 (0.4143)\tAccuracy 100.000 (98.438)\t\n",
            "Test: [4/11]\tLoss 0.7312 (0.4777)\tAccuracy 93.750 (97.500)\t\n",
            "Test: [5/11]\tLoss 0.2314 (0.4366)\tAccuracy 100.000 (97.917)\t\n",
            "Test: [6/11]\tLoss 0.9581 (0.5111)\tAccuracy 93.750 (97.321)\t\n",
            "Test: [7/11]\tLoss 0.9581 (0.5670)\tAccuracy 87.500 (96.094)\t\n",
            "Test: [8/11]\tLoss 2.3953 (0.7701)\tAccuracy 43.750 (90.278)\t\n",
            "Test: [9/11]\tLoss 0.8283 (0.7760)\tAccuracy 87.500 (90.000)\t\n",
            "Test: [10/11]\tLoss 0.3618 (0.7516)\tAccuracy 100.000 (90.588)\t\n",
            "  Validation : Accuracy1 90.588 Loss : 0.752 \n",
            "Save best model at /content/drive/My Drive/WS_DAN_PyTorch-master/checkpoint/bird/Resnet/model_best.pth.tar==\n",
            "Start epoch 1 ==========,lr=0.000900\n",
            "Epoch: [1][0/64]\tLoss 0.2074 (0.2074)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.005457878112792969 0.022546976804733276 0.19339129328727722\n",
            "Epoch: [1][4/64]\tLoss 0.1888 (0.2084)\tAccuracy 100.000 (100.000)\t\n",
            "loss1,loss2,feature_center_loss 0.0016086697578430176 0.019241929054260254 0.17837989330291748\n",
            "Traceback (most recent call last):\n",
            "  File \"train_bap.py\", line 255, in <module>\n",
            "    train()\n",
            "  File \"train_bap.py\", line 177, in train\n",
            "    train_prec, train_loss = engine.train(state, e)\n",
            "  File \"/content/drive/My Drive/WS_DAN_PyTorch-master/utils/engine.py\", line 42, in train\n",
            "    target = label.cuda()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh153r2Zwqt1"
      },
      "source": [
        "# Predict Script."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDxXjcrWogWA",
        "outputId": "95d81b98-6cb4-40ae-afa7-0a9f691431a3"
      },
      "source": [
        "%cd /content/drive/\"My Drive\"/WS_DAN_PyTorch-master\n",
        "!python train_bap.py predict\\\n",
        "    --model-name inception \\\n",
        "    --batch-size 12 \\\n",
        "    --dataset car \\\n",
        "    --image-size 400 \\\n",
        "    --input-size 400 \\\n",
        "    --checkpoint-path /content/drive/'My Drive'/WS_DAN_PyTorch-master/checkpoint/bird/model_best.pth.tar \\\n",
        "    --workers 4 \\\n",
        "    --parts 32 \\\n",
        "    --use-gpu \\\n",
        "    --multi-gpu \\\n",
        "    --gpu-ids 0 \\"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/WS_DAN_PyTorch-master\n",
            "100% 517/517 [02:27<00:00,  3.50it/s]\n",
            "Succesfully wrote Kaggle_attentionyou can upload this file to the kaggle competition website\n"
          ]
        }
      ]
    }
  ]
}